import os, sys, re, json,time
from dotenv import load_dotenv
from supabase import create_client
from keybert import KeyBERT
from collections import Counter
from crawler.integrated_crawler import save_articles_from_naver_parallel



# í™˜ê²½ ë³€ìˆ˜ ë° Supabase ì„¤ì •
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
load_dotenv()
supabase = create_client(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_KEY"))

# í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸
kw_model = KeyBERT(model='snunlp/KR-SBERT-V40K-klueNLI-augSTS')


def is_valid_keyword(word):
    if not word: return False
    if len(word) < 2 or len(word) > 10: return False
    if re.match(r"^\d", word): return False  # ìˆ«ìë¡œ ì‹œì‘
    if any(x in word for x in ["ë³´ë„", "ê¸°ì", "ë¶€ê³ ", "ìš´ì„¸", "ë‰´ìŠ¤", "afpbbnews"]): return False
    if re.search(r"[ê°€-í£]+(ì˜|ë¥¼|ì€|ëŠ”|ì´|ê°€|ì—|ë¡œ|ê³¼|ì™€|ë„)$", word): return False
    if any(x in word for x in ["ì–µ", "ì²œë§Œ", "ìœ„ì•ˆ", "ë‹¬ëŸ¬"]): return False
    if word.endswith(("ì„", "ë¥¼", "ì€", "ëŠ”", "ì´", "ê°€", "ì—", "ì˜", "ë¡œ")): return False
    return True

def get_keywords_for_query(query_keyword):
    response = supabase.table("test").select("article_keywords").eq("query_keyword", query_keyword).execute()
    print(f"ğŸ§© '{query_keyword}'ì— ëŒ€í•œ í–‰ ê°œìˆ˜:", len(response.data))

    keywords = []
    for row in response.data:
        if row["article_keywords"]:
            try:
                for kw in row["article_keywords"]:
                    if "keyword" in kw:
                        word = kw["keyword"].strip()
                        if 2 <= len(word) <= 15 and word != query_keyword:
                            keywords.append(word)
            except Exception as e:
                print(f"âš ï¸ í‚¤ì›Œë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
    print(f"ğŸ¯ ì¶”ì¶œëœ í‚¤ì›Œë“œ ìˆ˜ (ì „ì²˜ë¦¬ í›„): {len(keywords)})")
    return keywords

def get_top_similar_keywords(query_keyword, candidate_keywords, top_n=3, with_score=False):
    print("ğŸ” ìœ ì‚¬ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘")
    if not candidate_keywords:
        return []

    candidate_keywords = list(set([kw for kw in candidate_keywords if kw != query_keyword]))
    filtered_keywords = [kw for kw in candidate_keywords if is_valid_keyword(kw)]
    filtered_keywords = list(set(filtered_keywords))[:30]
    if not filtered_keywords:
        return []

    try:
        print(f"ğŸ§  ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...)")
        result = kw_model.extract_keywords(query_keyword, candidates=filtered_keywords, top_n=top_n)
    except Exception as e:
        print(f"âš ï¸ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
        result = []

    return result if with_score else [kw for kw, _ in result]


def expand_and_crawl_with_tree(query_keyword):
    print(f"âœ… ì‹œì‘: {query_keyword}")
    visited = set([query_keyword])

    # ë£¨íŠ¸ì—ì„œ ìì‹ 3ê°œ ì¶”ì¶œ
    level1_candidates = get_keywords_for_query(query_keyword)
    level1_results = get_top_similar_keywords(query_keyword, level1_candidates, top_n=2, with_score=True)

    children = []

    for i, (child_kw, child_score) in enumerate(level1_results):
        if child_kw in visited:
            continue
        visited.add(child_kw)
        print(f"ğŸŒ 1ì°¨ í¬ë¡¤ë§: {child_kw}")
        try:
            save_articles_from_naver_parallel(child_kw)
        except Exception as e:
            print(f"âŒ {child_kw} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

        # ìì‹ í‚¤ì›Œë“œì—ì„œ ì†ì£¼ 2ê°œ ì¶”ì¶œ
        level2_candidates = get_keywords_for_query(child_kw)
        level2_results = get_top_similar_keywords(child_kw, level2_candidates, top_n=2, with_score=True)

        grandchildren = []
        for j, (g_kw, g_score) in enumerate(level2_results):
            if g_kw in visited:
                continue
            visited.add(g_kw)
            print(f"ğŸŒ 2ì°¨ í¬ë¡¤ë§: {g_kw}")
            try:
                save_articles_from_naver_parallel(g_kw)
            except Exception as e:
                print(f"âŒ {g_kw} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            grandchildren.append({
                "name": g_kw,
                "score": round(g_score, 3)
            })

        children.append({
            "name": child_kw,
            "score": round(child_score, 3),
            "children": grandchildren
        })

    return {
        "tree": {
            "name": query_keyword,
            "score": 1.0,
            "children": children
        }
    }




