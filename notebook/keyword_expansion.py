import os, sys, re, json,time
from dotenv import load_dotenv
from supabase import create_client
from keybert import KeyBERT
from collections import Counter
from flask import jsonify



# í™˜ê²½ ë³€ìˆ˜ ë° Supabase ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from integrated_crawler import save_articles_from_naver_parallel

load_dotenv()
supabase = create_client(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_KEY"))

# í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸
kw_model = KeyBERT(model='snunlp/KR-SBERT-V40K-klueNLI-augSTS')


def is_valid_keyword(word):
    if not word: return False
    word = word.strip()
    if word in ["ì œëª©", "ì—†ìŒ"]: return False  # ì˜ë¯¸ ì—†ëŠ” í‚¤ì›Œë“œ
    if len(word) < 2 or len(word) > 10: return False
    if re.match(r"^\d", word): return False
    if any(x in word for x in ["ë³´ë„", "ê¸°ì", "ë¶€ê³ ", "ìš´ì„¸", "ë‰´ìŠ¤", "afpbbnews"]): return False
    if re.search(r"[ê°€-í£]+(ì˜|ë¥¼|ì€|ëŠ”|ì´|ê°€|ì—|ë¡œ|ê³¼|ì™€|ë„)$", word): return False
    if any(x in word for x in ["ì–µ", "ì²œë§Œ", "ìœ„ì•ˆ", "ë‹¬ëŸ¬"]): return False
    if word.endswith(("ì„", "ë¥¼", "ì€", "ëŠ”", "ì´", "ê°€", "ì—", "ì˜", "ë¡œ")): return False
    return True

def get_top_keywords_by_title(query_keyword, top_n=3):
    print(f"\nğŸ§© '{query_keyword}' ê´€ë ¨ ê¸°ì‚¬ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ")

    # Supabaseì—ì„œ query_keywordì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ë“¤ ë¶ˆëŸ¬ì˜¤ê¸°
    response = supabase.table("test").select("title").eq("query_keyword", query_keyword).execute()
    print(f"ğŸ“„ ì œëª© ìˆ˜: {len(response.data)}")

    word_counter = Counter()
    for row in response.data:
        title = row.get("title", "")
        words = re.findall(r"[ê°€-í£]{2,}", title)  # í•œê¸€ 2ê¸€ì ì´ìƒë§Œ ì¶”ì¶œ
        filtered = [w for w in words if is_valid_keyword(w) and w != query_keyword]
        word_counter.update(filtered)

    # ìƒìœ„ top_n ë°˜í™˜
    top_keywords = word_counter.most_common(top_n)
    
    print(f"ğŸ¯ ìµœë¹ˆë„ í‚¤ì›Œë“œ: {top_keywords}")
    if not top_keywords:
        return []
    
    return [{"name": kw, "score": round(freq / top_keywords[0][1], 3)} for kw, freq in top_keywords]

def store_keyword_graph(parent, children):
    for child in children:
        name = child.get("name", "").strip()
        if not name:  # ë¹ˆ ì´ë¦„ í•„í„°
            continue

        try:
            supabase.table("keyword_graph").insert({
                "query_keyword": name,
                "article_keywords": parent
            }).execute()
            print(f"âœ… ì €ì¥ ì„±ê³µ: {name}")
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {name} â†’", e)



# keyword_expansion.py

def expand_keywords(query_keyword):
    print(f"âœ… ì‹œì‘: {query_keyword}")
    
    graph = {
        query_keyword: {
            "primary": [],
            "secondary": []
        }
    }

    # ğŸ”¹ 1ì°¨ í™•ì¥
    primary_keywords = get_top_keywords_by_title(query_keyword)
    print(f"ğŸ”¹ primary: {primary_keywords}")
    graph[query_keyword]["primary"] = [kw["name"] for kw in primary_keywords]

    for primary in primary_keywords:
        p_name = primary["name"]
        graph[p_name] = {"primary": [], "secondary": []}

        try:
            # ğŸ”¹ 2ì°¨ í™•ì¥ (secondary)
            secondary_keywords = get_top_keywords_by_title(p_name)
            print(f"ğŸ”¸ secondary ({p_name}): {secondary_keywords}")
            graph[p_name]["secondary"] = [kw["name"] for kw in secondary_keywords]
        except Exception as e:
            print(f"âŒ secondary í™•ì¥ ì‹¤íŒ¨ ({p_name}):", e)
            graph[p_name]["secondary"] = []

    print(f"âœ… ê·¸ë˜í”„ ì™„ì„±: {graph}")
    return graph
